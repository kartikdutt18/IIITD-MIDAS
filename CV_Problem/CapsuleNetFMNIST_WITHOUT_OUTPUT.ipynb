{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsuleNetFMNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XuCnU6GCY_7b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Uploading All files:**\n",
        "Upload all test/train pickle files."
      ]
    },
    {
      "metadata": {
        "id": "y2o2ElhV8j1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAAuwconcrZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o1EwlzpIzSBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mr6WaEejdS5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Understanding the Data**"
      ]
    },
    {
      "metadata": {
        "id": "yDPgKS3BZMNb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Load Train:**\n",
        "Load all pickle files and returns the pickle file as list"
      ]
    },
    {
      "metadata": {
        "id": "3dnI59-kAKRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def load_train(fName):\n",
        "  \"\"\"\n",
        "    fName:Name/Relative Path for loading the file\n",
        "  \"\"\"\n",
        "  pickle_in=open(fName,'rb')\n",
        "  train_image=pickle.load(pickle_in)\n",
        "  return train_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HUdlvOIL8ofK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  train_image: Contains all training images.\n",
        "  train_labels:Contains labels for training images\n",
        "  testing_image: Contains all testing images.\n",
        "\"\"\"\n",
        "train_image=load_train('train_image.pkl')\n",
        "train_label=load_train('train_label.pkl')\n",
        "test_image=load_train('test_image.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQTAXwYvc9F0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **See Count:**\n",
        "Prints no. of images corresponding to each class(Training Class Distribution)."
      ]
    },
    {
      "metadata": {
        "id": "6IgkaM2S9ITk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def see_count(li):\n",
        "  count=[0 for _ in range(7)]\n",
        "  for i in range(len(li)):\n",
        "    count[li[i]]+=1\n",
        "  print(count)\n",
        "see_count(train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-lJiXE7eEND",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Show Images:**\n",
        "Plots 2 images of each category"
      ]
    },
    {
      "metadata": {
        "id": "m27u4RWlex-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def show_images():\n",
        "  \"\"\"\n",
        "    columns:No of Columns in Figure\n",
        "    rows:No of rows in figure.\n",
        "  \"\"\"\n",
        "  columns = 4\n",
        "  rows = 2\n",
        "  fig=plt.figure(figsize=(14, 14))\n",
        "  for i in range(1, columns*rows+1):\n",
        "    img=train_image[i*1000-1]\n",
        "    img=np.reshape(img,(28,28))\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.xlabel(train_label[i*1000-1])\n",
        "    plt.imshow(img,interpolation='nearest')\n",
        "  plt.show()\n",
        "show_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yxt_YpjgfU5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Encode Labels:**\n",
        "Return a list with all labels between 0 and 3 (There are only 4 classes)"
      ]
    },
    {
      "metadata": {
        "id": "0CuRGw1Q493z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encode_labels(train_label):\n",
        "  train_new_label=train_label\n",
        "  for i in range(len(train_label)):\n",
        "    if train_label[i]==2:\n",
        "      train_new_label[i]=1\n",
        "    elif  train_label[i]==3:\n",
        "      train_new_label[i]=2\n",
        "    elif train_label[i]==6:\n",
        "      train_new_label[i]=3\n",
        "    else:continue\n",
        "  return train_new_label\n",
        "\n",
        "train_label=encode_labels(train_label)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WTnEc1Xf5liv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_pickle(obj,fName):\n",
        "  \"\"\"\n",
        "    obj: list that will be dumped in pickle file\n",
        "    fName:NAme of pickle file with extention\n",
        "  \"\"\"\n",
        "  pickle_train_label=open(fName,\"wb\")\n",
        "  pickle.dump(obj,pickle_train_label)\n",
        "  pickle_train_label.close()\n",
        "  \n",
        "save_pickle(train_label,\"train_label_enc.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pOUhBffkifG1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Defining the Capsule Network: **"
      ]
    },
    {
      "metadata": {
        "id": "MK5EhYB7ioLW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Installing and importing libraries**"
      ]
    },
    {
      "metadata": {
        "id": "56_FNNEejaG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from numpy import prod\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from datetime import datetime\n",
        "from time import time\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import set_matplotlib_close"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ruTiT75fCg7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Squash:**\n",
        "The non-linear activation used in Capsule Network.\n",
        "It drives the length of a large vector to near 1 and small vector to 0.\n",
        "Returns the squashed vector."
      ]
    },
    {
      "metadata": {
        "id": "kTvVM7xnjt13",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def squash(vec,dim=-1):\n",
        "  \"\"\"\n",
        "    dim: Axis along which vector is squashed.\n",
        "    vec:N dim vector to be squashed\n",
        "  \"\"\"\n",
        "  squared_normal=torch.sum(vec**2,dim=dim,keepdim=True)\n",
        "  fn=squared_normal / (1 + squared_normal) * vec / (torch.sqrt(squared_normal) + 1e-8)\n",
        "  return fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5L8tmyOtDqLP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Primary Capsules:**\n",
        "Produces combinations of features from convolution.\n",
        "Returns vector after being passed through 9x9x256 convolutional kernels or in general terms:\n",
        "Returns: output tensor of shape=size=[batch, num_caps, dim_caps]"
      ]
    },
    {
      "metadata": {
        "id": "Iy8ULZYgjzi6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PrimaryCapsules(nn.Module):\n",
        "  def __init__(self,in_channels, out_channels, dim_caps,kernel_size=9, stride=2, padding=0):\n",
        "    \"\"\"\n",
        "      dim:dimension of the output vectors of the capsules in this layer\n",
        "      in_channels:Input channel size\n",
        "      out_channels: output channel size\n",
        "    \"\"\"\n",
        "    super(PrimaryCapsules,self).__init__()\n",
        "    self.dim_caps=dim_caps\n",
        "    self._caps_channel = int(out_channels / dim_caps)\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out=self.conv(x)\n",
        "    out = out.view(out.size(0), self._caps_channel, out.size(2), out.size(3), self.dim_caps)\n",
        "    #Arranging output as [batch, num_caps, dim_caps] and sqaushing it.\n",
        "    out = out.view(out.size(0), -1, self.dim_caps)\n",
        "    out=squash(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4wYun6s6I3nI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ** Router:**\n",
        " The routing algorithm in Capsule network.\n",
        " Returns A Tensor of shape [batch_size, num_caps, dim_caps,1]"
      ]
    },
    {
      "metadata": {
        "id": "FCVMveP4j2qQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Router(nn.Module):\n",
        "  def __init__(self,in_dim, in_caps, num_caps, dim_caps, num_routing,device: torch.device):\n",
        "      super(Router,self).__init__()\n",
        "      self.in_dim = in_dim\n",
        "      self.in_caps = in_caps\n",
        "      self.num_caps = num_caps\n",
        "      self.dim_caps = dim_caps\n",
        "      self.num_routing = num_routing\n",
        "      self.device = device\n",
        "      self.W = nn.Parameter( 0.01 * torch.randn(1, num_caps, in_caps, dim_caps, in_dim ))\n",
        "    \n",
        "  def __repr__(self):\n",
        "      # representation of router.\n",
        "      tab= '  '\n",
        "      line = '\\n'\n",
        "      next = ' -> '\n",
        "      res = self.__class__.__name__ + '('\n",
        "      res = res + line + tab + '(' + str(0) + '): ' + 'CapsuleLinear('\n",
        "      res = res + str(self.in_dim) + ', ' + str(self.dim_caps) + ')'\n",
        "      res = res + line + tab + '(' + str(1) + '): ' + 'Routing('\n",
        "      res = res + 'Routing No =' + str(self.num_routing) + ')'\n",
        "      res = res + line + ')'\n",
        "      return res\n",
        "  \n",
        "  def forward(self,x):\n",
        "    batch_size = x.size(0)\n",
        "    x = x.unsqueeze(1).unsqueeze(4)\n",
        "    # W @ x =(1, num_caps, in_caps, dim_caps, in_dim) @ (batch_size, 1, in_caps, in_dim, 1) =(batch_size, num_caps, in_caps, dim_caps, 1)\n",
        "    u_hat = torch.matmul(self.W, x)\n",
        "    u_hat = u_hat.squeeze(-1)\n",
        "    #Prevent flow of Gradients\n",
        "    temp_u_hat = u_hat.detach()\n",
        "    b = torch.zeros(batch_size, self.num_caps, self.in_caps, 1).to(self.device)\n",
        "    \n",
        "    for route_iter in range(self.num_routing-1):\n",
        "      sc = F.softmax(b, dim=1)\n",
        "      # (batch_size, num_caps, in_caps, 1) * (batch_size, in_caps, num_caps, dim_caps) =(batch_size, num_caps, in_caps, dim_caps) sum across in_caps ->(batch_size, num_caps, dim_caps)\n",
        "      vec = (sc * temp_u_hat).sum(dim=2)\n",
        "      v = squash(vec)\n",
        "      uv = torch.matmul(temp_u_hat, v.unsqueeze(-1))\n",
        "      b += uv\n",
        "      \n",
        "    sc = F.softmax(b, dim=1)\n",
        "    vec = (sc * u_hat).sum(dim=2)\n",
        "    v = squash(vec)\n",
        "    return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVvOUb53Ku_j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **CapsuleNet:**\n",
        "Defining the architecture of network."
      ]
    },
    {
      "metadata": {
        "id": "hqmX7-e4j3dZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsuleNet(nn.Module):\n",
        "\tdef __init__(self, img_shape, channels, primary_dim, num_classes, out_dim, num_routing,device= torch.device, kernel_size=9):\n",
        "     \"\"\"\n",
        "      channel: data size = [channels, width, height]\n",
        "      num_classes: number of classes\n",
        "      num_routing:number of routing calls\n",
        "      img_shape:Shape of image from dataloader\n",
        "      primary:Primary Capsule\n",
        "      Decoder:Decoder part of capsulenet\n",
        "     \"\"\"\n",
        "\t\tsuper(CapsuleNet,self).__init__()\n",
        "\t\tself.img_shape = img_shape\n",
        "\t\tself.num_classes = num_classes;self.device = device\n",
        "    \n",
        "\t\tself.conv1 = nn.Conv2d(img_shape[0], channels, kernel_size, stride=1, bias=True)\n",
        "\t\tself.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "\t\tself.primary = PrimaryCapsules(channels, channels, primary_dim, kernel_size)\n",
        "\t\t\n",
        "    \n",
        "        \n",
        "\t\tprimary_caps = int(channels / primary_dim * ( img_shape[1] - 2*(kernel_size-1) ) * ( img_shape[2] - 2*(kernel_size-1) ) / 4)\n",
        "    \n",
        "    \n",
        "\t\tself.digits = Router(primary_dim, primary_caps, num_classes, out_dim, num_routing,device=device)\n",
        "    \n",
        "\t\tself.decoder = nn.Sequential(\n",
        "\t\t\tnn.Linear(out_dim * num_classes, 512),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Linear(512, 1024),\n",
        "\t\t\tnn.ReLU(inplace=True),\n",
        "\t\t\tnn.Linear(1024, int(prod(img_shape)) ),\n",
        "\t\t\tnn.Sigmoid()\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tout = self.conv1(x)\n",
        "\t\tout = self.relu(out)\n",
        "\t\tout = self.primary(out)\n",
        "\t\tout = self.digits(out)\n",
        "\t\tpreds = torch.norm(out, dim=-1)\n",
        "\n",
        "\t\t# Reconstruct the predicted image and generate label\n",
        "\t\t_, max_length_idx = preds.max(dim=1)\t\n",
        "\t\ty = torch.eye(self.num_classes).to(self.device)\n",
        "\t\ty = y.index_select(dim=0, index=max_length_idx).unsqueeze(2)\n",
        "\n",
        "\t\treconstructions = self.decoder( (out*y).view(out.size(0), -1) )\n",
        "\t\treconstructions = reconstructions.view(-1, *self.img_shape)\n",
        "\n",
        "\t\treturn preds, reconstructions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIFUAzxTOz7M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Margin Loss:**\n",
        "The length of the instantiation vector represents the\n",
        "probability that a capsule’s entity exists, so we need\n",
        "top-level capsule for digit class k to have a long\n",
        "instantiation vector iff that digit is present in the image. Returns margin loss of function."
      ]
    },
    {
      "metadata": {
        "id": "E6lL5eAgj6TE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MarginLoss(nn.Module):\n",
        "    def __init__(self, size_average=False, loss_lambda=0.5):\n",
        "            super(MarginLoss,self).__init__()\n",
        "            self.size_average = size_average\n",
        "            self.m_plus = 0.9\n",
        "            self.m_minus = 0.1\n",
        "            self.loss_lambda = loss_lambda\n",
        "    \n",
        "    def forward(self,inputs,labels):\n",
        "          L_k = labels * F.relu(self.m_plus - inputs)**2 + self.loss_lambda * (1 - labels) * F.relu(inputs - self.m_minus)**2\n",
        "          L_k.sum(dim=1)\n",
        "\n",
        "          if self.size_average:return L_k.mean()\n",
        "          else:return L_k.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6KPgOm3WWsqD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Capsule Loss:**\n",
        "Returns Scalar value of  Margin loss + loss_lambda * reconstruction loss."
      ]
    },
    {
      "metadata": {
        "id": "lkGoEk-rj8lJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsuleLoss(nn.Module):\n",
        "\tdef __init__(self,loss_lambda=0.5, recon_loss_scale=5e-4, size_average=False):\n",
        "\t\tsuper(CapsuleLoss,self).__init__()\n",
        "\t\tself.size_average = size_average\n",
        "\t\tself.margin_loss = MarginLoss(size_average=size_average, loss_lambda=loss_lambda)\n",
        "\t\tself.reconstruction_loss = nn.MSELoss(size_average=size_average)\n",
        "\t\tself.recon_loss_scale = recon_loss_scale\n",
        "\n",
        "\tdef forward(self,inputs, labels, images, reconstructions):\n",
        "\t\tmargin_loss = self.margin_loss(inputs, labels)\n",
        "\t\treconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
        "\t\tcaps_loss = (margin_loss + self.recon_loss_scale * reconstruction_loss)\n",
        "\n",
        "\t\treturn caps_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KwlDjhaPXPz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Delete Old:**\n",
        "Deletes old models/Checkpoints and downloads model every 50 epochs."
      ]
    },
    {
      "metadata": {
        "id": "PjlSHSZcrlTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def delete_old(li,epochs,accs):\n",
        "  \"\"\"\n",
        "    SAVE_MODEL_PATH:Path for storing and accessing models\n",
        "    DELETE_MODEL_PATH:Path for deleting previous models\n",
        "  \"\"\"\n",
        "  SAVE_MODEL_PATH='Checkpoints/'\n",
        "  if epochs%50==0:\n",
        "    #files.download(os.path.join(SAVE_MODEL_PATH, f'{epochs}_{accs}.pth'));\n",
        "    for i in range(30):\n",
        "      epoch=li[0]\n",
        "      accuracy=li[2]\n",
        "      DELETE_MODEL_PATH=os.path.join(SAVE_MODEL_PATH, f'{epoch}_{accuracy}.pth')\n",
        "      #if os.path.exists(DELETE_MODEL_PATH):\n",
        "       # os.remove(DELETE_MODEL_PATH)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5cLEuY7X2FP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Save Model PY:**\n",
        "Saves models as state dictionary so that they can be retrained."
      ]
    },
    {
      "metadata": {
        "id": "5uVqWGsV0Vzq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_model_py(model,optimizer,loss,epoch,accuracy):\n",
        "  SAVE_MODEL_PATH='Checkpoints/'\n",
        "  if epoch%1000:\n",
        "    PATH=os.path.join(SAVE_MODEL_PATH, f'{epoch}_{accuracy}_Load.pth')\n",
        "    torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': loss}, PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Do0xX9oYGm7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Plot Epoch Loss:**\n",
        "Plots train and test accuracy by accepting training/testing history."
      ]
    },
    {
      "metadata": {
        "id": "vdw8z5nZ1s4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "set_matplotlib_close(True)\n",
        "from IPython.display import display\n",
        "def plot_epoch_loss(history):\n",
        "  \"\"\"\n",
        "    history: list of format [epochs,loss,epoch,phase:\"train/test\"]\n",
        "  \"\"\"\n",
        "  x_train_acc=x_test_acc=[]\n",
        "  x_train_loss=x_test_loss=[]\n",
        "  y_train=y_test=[]\n",
        "  for a in history:\n",
        "    if a[3]=='train':\n",
        "      x_train_acc.append(a[2]*100)\n",
        "      x_train_loss.append(a[1])\n",
        "      y_train.append(a[0])\n",
        "    else:\n",
        "      x_test_acc.append(a[2]*100)\n",
        "      x_test_loss.append(a[1])\n",
        "      y_test.append(a[0])\n",
        "  plt.figure(1)\n",
        "  plt.subplot(221)\n",
        "  plt.plot(y_train,x_train_acc,color='r')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Train Accuracy')\n",
        "  plt.subplot(222)\n",
        "  plt.plot(y_test,x_test_acc,color='b')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title('Test Accuracy')\n",
        "  plt.subplot(223)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Train Loss')\n",
        "  plt.plot(y_train,x_train_loss ,color='r')\n",
        "  plt.subplot(224)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.title('Test Loss')\n",
        "  plt.plot(y_test,x_test_loss ,color='b')\n",
        "  display(plt.show())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X4pxPJQsaEp4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Trainer:**\n",
        "Wrapper object for handling training and evaluation.Trains/tests the network and returns trained network."
      ]
    },
    {
      "metadata": {
        "id": "K0ESE_4jj_Aa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists('Checkpoints/'):os.mkdir('Checkpoints/')\n",
        "SAVE_MODEL_PATH='Checkpoints/'\n",
        "history=[]\n",
        "class Trainer:\n",
        "\t\"\"\"\n",
        "\tnet:Capsule network object.\n",
        "  loaders:list of DataLoaders\n",
        "  img_shape:Shape of image\n",
        "  critireon: Capsule Loss\n",
        "  num_classes:Number of classes\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, loaders, batch_size,learning_rate, num_routing=3, lr_decay=0.9,num_classes=4, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), multi_gpu=(torch.cuda.device_count() > 1)):\n",
        "\t\tself.device = device\n",
        "\t\tself.multi_gpu = multi_gpu\n",
        "\n",
        "\t\tself.loaders = loaders\n",
        "\t\timg_shape = self.loaders['train'].dataset[0][0].numpy().shape\n",
        "\t\t\n",
        "\t\tself.net = CapsuleNet(img_shape=img_shape, channels=256, primary_dim=8, num_classes=num_classes, out_dim=16, num_routing=num_routing, device=self.device).to(self.device)\n",
        "\t\tif os.path.exists(os.path.join(SAVE_MODEL_PATH,'best_prev.pth')):MODEL_LOAD_PATH=os.path.join(SAVE_MODEL_PATH,'best_prev.pth');self.net = torch.load(MODEL_LOAD_PATH);print('Model Loaded')\n",
        "\t\tif self.multi_gpu:\n",
        "\t\t\tself.net = nn.DataParallel(self.net)\n",
        "    \n",
        "\t\tself.criterion = CapsuleLoss(loss_lambda=0.5, recon_loss_scale=5e-4)\n",
        "\t\tself.optimizer = optim.Adam(self.net.parameters(), lr=learning_rate)\n",
        "\t\tself.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=lr_decay)\n",
        "\t\tprint(8*'#', 'PyTorch Model built'.upper(), 8*'#')\n",
        "\t\tprint('Num params:', sum([prod(p.size()) for p in self.net.parameters()]))\n",
        "\t\n",
        "\tdef __repr__(self):\n",
        "\t\treturn repr(self.net)\n",
        "\n",
        "\tdef run(self, epochs, classes):\n",
        "\t\tprint(8*'#', 'Run started'.upper(), 8*'#')\n",
        "\t\teye = torch.eye(len(classes)).to(self.device)\n",
        "\t\t\n",
        "\t\tfor epoch in range(1, epochs+1):\n",
        "\t\t\tfor phase in ['train', 'test']:\n",
        "\t\t\t\tprint(f'{phase}ing...'.capitalize())\n",
        "\t\t\t\tif phase == 'train':\n",
        "\t\t\t\t\tself.net.train()\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tself.net.eval()\n",
        "\n",
        "\t\t\t\tt0 = time()\n",
        "\t\t\t\trunning_loss = 0.0\n",
        "\t\t\t\tcorrect = 0; total = 0\n",
        "\t\t\t\tfor i, (images, labels) in enumerate(self.loaders[phase]):\n",
        "\t\t\t\t\tt1 = time()\n",
        "\t\t\t\t\timages, labels = images.to(self.device), labels.to(self.device)\n",
        "\t\t\t\t\t# One-hot encode labels\n",
        "\t\t\t\t\tlabels = eye[labels]\n",
        "\n",
        "\t\t\t\t\tself.optimizer.zero_grad()\n",
        "\n",
        "\t\t\t\t\toutputs, reconstructions = self.net(images)\n",
        "\t\t\t\t\tloss = self.criterion(outputs, labels, images, reconstructions)\n",
        "\n",
        "\t\t\t\t\tif phase == 'train':\n",
        "\t\t\t\t\t\tloss.backward()\n",
        "\t\t\t\t\t\tself.optimizer.step()\n",
        "\n",
        "\t\t\t\t\trunning_loss += loss.item()\n",
        "\n",
        "\t\t\t\t\t_, predicted = torch.max(outputs, 1)\n",
        "\t\t\t\t\t_, labels = torch.max(labels, 1)\n",
        "\t\t\t\t\ttotal += labels.size(0)\n",
        "\t\t\t\t\tcorrect += (predicted == labels).sum()\n",
        "\t\t\t\t\taccuracy = float(correct) / float(total)\n",
        "\n",
        "\t\t\t\t\tif phase == 'train':\n",
        "\t\t\t\t\t\tif i%100==0:clear_output();print(8*'#', 'Run started'.upper(), 8*'#');print(f'{phase}ing...'.capitalize());plot_epoch_loss(history);\t\t\t\t\n",
        "\t\t\t\t\t\tprint(f'Epoch {epoch}, Batch {i+1}, Loss {running_loss/(i+1)}',f'Accuracy {accuracy} Time {round(time()-t1, 3)}s');\n",
        "\t\t\t\thistory.append([epoch,running_loss/i+1,accuracy,phase]);plot_epoch_loss(history);\n",
        "\t\t\t\tif epoch%10==0:torch.save(self.net, os.path.join(SAVE_MODEL_PATH, f'{epoch}_{accuracy}.pth'));delete_old(history,epoch,accuracy);#save_model_py(self.net,epoch,accuracy); \n",
        "\t\t\t\tprint(f'{phase.upper()} Epoch {epoch}, Loss {running_loss/(i+1)}',f'Accuracy {accuracy} Time {round(time()-t0, 2)}s')\n",
        "        \n",
        "\t\t\tself.scheduler.step()\n",
        "\t\tnow = str(datetime.now()).replace(\" \", \"-\")\n",
        "\t\terror_rate = round((1-accuracy)*100, 2)\n",
        "\t\ttorch.save(self.net, os.path.join(SAVE_MODEL_PATH,'best_prev_1.pth'))\n",
        "\n",
        "\t\tclass_correct = list(0. for _ in classes)\n",
        "\t\tclass_total = list(0. for _ in classes)\n",
        "\t\tfor images, labels in self.loaders['test']:\n",
        "\t\t\timages, labels = images.to(self.device), labels.to(self.device)\n",
        "\n",
        "\t\t\toutputs, reconstructions = self.net(images)\n",
        "\t\t\t_, predicted = torch.max(outputs, 1)\n",
        "\t\t\tc = (predicted == labels).squeeze()\n",
        "\t\t\tfor i in range(labels.size(0)):\n",
        "\t\t\t\tlabel = labels[i]\n",
        "\t\t\t\tclass_correct[label] += c[i].item()\n",
        "\t\t\t\tclass_total[label] += 1\n",
        "\t\tfor i in range(len(classes)):\n",
        "\t\t\tprint('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]));return self.net\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2jnVAW7odBmn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **FashionMNIST:**\n",
        "Loads Pickle File and returns image and label after reshaping."
      ]
    },
    {
      "metadata": {
        "id": "HHGhk0QxkDnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FashionMNIST(Dataset):\n",
        "    def __init__(self, pickle_file_images,pickle_file_labels,train=False, transform=None):\n",
        "        pickle_in=open(pickle_file_images,'rb')\n",
        "        pickle_in_label=open(pickle_file_labels,'rb')\n",
        "        self.train_image=pickle.load(pickle_in)\n",
        "        self.label=pickle.load(pickle_in_label)\n",
        "        self.transform = transform\n",
        "        self.train=train\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "    def __getitem__(self, idx):\n",
        "      image = self.train_image[idx]\n",
        "      image=np.array(image,dtype=np.uint8)\n",
        "      #image=image.reshape(28,28)\n",
        "      #image=augment_img(image)\n",
        "      image=image.reshape(28,28,1)\n",
        "      if self.train:\n",
        "        seq = iaa.Sequential([iaa.Fliplr(0.5),iaa.Sometimes(0.5,iaa.GaussianBlur(sigma=(0, 0.5))),iaa.ContrastNormalization((0.75, 1.5)),iaa.Multiply((0.8, 1.2), per_channel=0.2),iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},rotate=(-25, 25),shear=(-8, 8))], random_order=True)\n",
        "        images_aug = seq.augment_images([image])\n",
        "        images_aug=images_aug[0]\n",
        "        \n",
        "      label = self.label[idx]\n",
        "      if self.transform is not None:\n",
        "          image = self.transform(image)\n",
        "      return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GXu42WDYdOTq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Train Test Split:**\n",
        "Splits train images into training set and test set."
      ]
    },
    {
      "metadata": {
        "id": "bZnUrQCrubus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_test_split(train_images,train_labels,split_ratio=0.90):\n",
        "  \"\"\"\n",
        "    train_images:Set of training images\n",
        "    train_labels:training labels\n",
        "    split_ratio:Training_set_size/total_size\n",
        "  \"\"\"\n",
        "  split=int((1-split_ratio)*len(train_image))\n",
        "  train_image_split=[]\n",
        "  train_label_split=[]\n",
        "  test_image_split=[]\n",
        "  test_label_split=[]\n",
        "  count=0\n",
        "  np.random.seed(21)\n",
        "  for i in range(len(train_labels)):\n",
        "    if count<split:\n",
        "      arr=[1,1,1,1,1,1,1,1,1,1,0,1,1]\n",
        "      k=len(arr)\n",
        "      in_train=arr[np.random.randint(k)]\n",
        "      if in_train:\n",
        "        train_image_split.append(train_images[i])\n",
        "        train_label_split.append(train_labels[i])\n",
        "      else:\n",
        "          test_image_split.append(train_images[i])\n",
        "          test_label_split.append(train_labels[i])\n",
        "          count+=1\n",
        "    else:\n",
        "      train_image_split.append(train_images[i])\n",
        "      train_label_split.append(train_labels[i])\n",
        "  save_pickle(train_image_split,\"train_image_nin.pkl\")\n",
        "  save_pickle(train_label_split,\"train_label_nin.pkl\")\n",
        "  save_pickle(test_image_split,\"test_image_nin.pkl\")\n",
        "  save_pickle(test_label_split,\"test_label_nin.pkl\")\n",
        "  print(\"Train Class Distribution\")\n",
        "  see_count(train_label_split)\n",
        "  print(\"Test Class Distribution\")\n",
        "  see_count(test_label_split)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fz-7LLE4fk3X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_test_split(train_image,train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfeC20ESdve0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Loading the Data:**\n",
        "Loads the pickle file and creates Dataloaders.\n",
        "**Augmentation Used:**\n",
        "Random Rotation,Random Vertical Flip,Random Vertical Flip,Color Jitter(adjust brightness,hue and contrast)."
      ]
    },
    {
      "metadata": {
        "id": "8y4bcI7eqMXu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BatchSize=batch_size=64\n",
        "size = 28\n",
        "classes = list(range(4))\n",
        "loader={}\n",
        "mean, std = ( ( 0.5,), ( 0.5,) )\n",
        "augmentation=transforms.Compose([transforms.RandomOrder([transforms.RandomVerticalFlip(p=0.001),transforms.RandomRotation(degrees=(-10,10)),transforms.RandomHorizontalFlip(p=0.2),transforms.ColorJitter(brightness=0,contrast=0)])])\n",
        "trainset=FashionMNIST( pickle_file_images='train_image_nin.pkl',pickle_file_labels=\"train_label_nin.pkl\",train=True, transform=transforms.Compose([transforms.ToPILImage(),augmentation,transforms.ToTensor()]))\n",
        "loader['train'] = torch.utils.data.DataLoader(trainset, batch_size=BatchSize,shuffle=True)\n",
        "augmentation_2=transforms.Compose([transforms.RandomOrder([transforms.RandomVerticalFlip(p=0.001),transforms.RandomRotation(degrees=(-8,8)),transforms.RandomHorizontalFlip(p=0.2),transforms.ColorJitter(brightness=0,contrast=0)])])\n",
        "testset=FashionMNIST( pickle_file_images='test_image_nin.pkl',pickle_file_labels=\"test_label_nin.pkl\",train=False, transform=transforms.Compose([transforms.ToPILImage(),augmentation_2,transforms.ToTensor()]))\n",
        "loader['test']= torch.utils.data.DataLoader(testset, batch_size=BatchSize,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXWhWLLxQuQ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GFitSMYDePsm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Calling Trainer**"
      ]
    },
    {
      "metadata": {
        "id": "11KFiMD6yP-2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs=150\n",
        "classes = list(range(4))\n",
        "learning_rate=7e-4\n",
        "lr_decay=0.95\n",
        "history=[]\n",
        "caps_net=Trainer(loader,num_classes=4,batch_size=128,learning_rate=learning_rate,num_routing=3, lr_decay=lr_decay)\n",
        "net=caps_net.run(epochs=epochs, classes=classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gMjVD3qA23R5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDTOkzhCgZK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Inference:**\n",
        "Loads pickle file and generates prediction."
      ]
    },
    {
      "metadata": {
        "id": "94HmA4RL18OB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inference(fName):\n",
        "  final_label=[]\n",
        "  decode=[0,2,3,6]\n",
        "  test_image=load_train(fName)\n",
        "  for idx in range(len(test_image)):\n",
        "    image=test_image[idx]\n",
        "    image=np.array(image,dtype=np.uint8)\n",
        "    image=torch.from_numpy(image)\n",
        "    image=image.type(torch.cuda.FloatTensor)\n",
        "    image=image.reshape(1,1,28,28)\n",
        "    outputs, reconstructions = net(image)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    final_prediction=decode[predicted]\n",
        "    final_label.append(final_prediction)\n",
        "  save_pickle(final_label,\"kartikdutt.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XWQk6AcLEGPq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create Submission**\n",
        "Loads prediction and creates CSV file"
      ]
    },
    {
      "metadata": {
        "id": "I2BbYSWBQdu3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def create_submission(fName):\n",
        "  final_pred=load_train(\"kartikdutt.pkl\")\n",
        "  column_name=['image_index','class']\n",
        "  df=pd.DataFrame(columns=column_name)\n",
        "  for i in range(len(final_pred)):\n",
        "    df=df.append({column_name[0]:i,column_name[1]:final_pred[i]},ignore_index=True)\n",
        "  df.to_csv('kartik_dutt.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwUjo3QEVRHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inference('test_image.pkl')\n",
        "create_submission(\"kartikdutt.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJBoAzUbiEgP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('kartik_dutt.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}